{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":90274,"databundleVersionId":10995111,"sourceType":"competition"}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:49:50.698449Z","iopub.execute_input":"2025-02-28T04:49:50.698907Z","iopub.status.idle":"2025-02-28T04:49:50.706485Z","shell.execute_reply.started":"2025-02-28T04:49:50.698872Z","shell.execute_reply":"2025-02-28T04:49:50.705570Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/playground-series-s5e2/sample_submission.csv\n/kaggle/input/playground-series-s5e2/train.csv\n/kaggle/input/playground-series-s5e2/test.csv\n/kaggle/input/playground-series-s5e2/training_extra.csv\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:49:50.707767Z","iopub.execute_input":"2025-02-28T04:49:50.708098Z","iopub.status.idle":"2025-02-28T04:49:50.771846Z","shell.execute_reply.started":"2025-02-28T04:49:50.708075Z","shell.execute_reply":"2025-02-28T04:49:50.770809Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"df_train=pd.read_csv('/kaggle/input/playground-series-s5e2/train.csv')\ndf_test=pd.read_csv('/kaggle/input/playground-series-s5e2/test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:49:50.773412Z","iopub.execute_input":"2025-02-28T04:49:50.773694Z","iopub.status.idle":"2025-02-28T04:49:51.462134Z","shell.execute_reply.started":"2025-02-28T04:49:50.773665Z","shell.execute_reply":"2025-02-28T04:49:51.460827Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"df_train.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:49:51.463937Z","iopub.execute_input":"2025-02-28T04:49:51.464268Z","iopub.status.idle":"2025-02-28T04:49:51.478334Z","shell.execute_reply.started":"2025-02-28T04:49:51.464243Z","shell.execute_reply":"2025-02-28T04:49:51.477462Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"   id         Brand Material    Size  Compartments Laptop Compartment  \\\n0   0      Jansport  Leather  Medium           7.0                Yes   \n1   1      Jansport   Canvas   Small          10.0                Yes   \n2   2  Under Armour  Leather   Small           2.0                Yes   \n3   3          Nike    Nylon   Small           8.0                Yes   \n4   4        Adidas   Canvas  Medium           1.0                Yes   \n\n  Waterproof      Style  Color  Weight Capacity (kg)      Price  \n0         No       Tote  Black             11.611723  112.15875  \n1        Yes  Messenger  Green             27.078537   68.88056  \n2         No  Messenger    Red             16.643760   39.17320  \n3         No  Messenger  Green             12.937220   80.60793  \n4        Yes  Messenger  Green             17.749338   86.02312  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Brand</th>\n      <th>Material</th>\n      <th>Size</th>\n      <th>Compartments</th>\n      <th>Laptop Compartment</th>\n      <th>Waterproof</th>\n      <th>Style</th>\n      <th>Color</th>\n      <th>Weight Capacity (kg)</th>\n      <th>Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Jansport</td>\n      <td>Leather</td>\n      <td>Medium</td>\n      <td>7.0</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Tote</td>\n      <td>Black</td>\n      <td>11.611723</td>\n      <td>112.15875</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Jansport</td>\n      <td>Canvas</td>\n      <td>Small</td>\n      <td>10.0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Messenger</td>\n      <td>Green</td>\n      <td>27.078537</td>\n      <td>68.88056</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Under Armour</td>\n      <td>Leather</td>\n      <td>Small</td>\n      <td>2.0</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Messenger</td>\n      <td>Red</td>\n      <td>16.643760</td>\n      <td>39.17320</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Nike</td>\n      <td>Nylon</td>\n      <td>Small</td>\n      <td>8.0</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Messenger</td>\n      <td>Green</td>\n      <td>12.937220</td>\n      <td>80.60793</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Adidas</td>\n      <td>Canvas</td>\n      <td>Medium</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Messenger</td>\n      <td>Green</td>\n      <td>17.749338</td>\n      <td>86.02312</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"df_test.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:49:51.479354Z","iopub.execute_input":"2025-02-28T04:49:51.479680Z","iopub.status.idle":"2025-02-28T04:49:51.505549Z","shell.execute_reply.started":"2025-02-28T04:49:51.479655Z","shell.execute_reply":"2025-02-28T04:49:51.504509Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"       id   Brand Material    Size  Compartments Laptop Compartment  \\\n0  300000    Puma  Leather   Small           2.0                 No   \n1  300001    Nike   Canvas  Medium           7.0                 No   \n2  300002  Adidas   Canvas   Large           9.0                 No   \n3  300003  Adidas    Nylon   Large           1.0                Yes   \n4  300004     NaN    Nylon   Large           2.0                Yes   \n\n  Waterproof      Style  Color  Weight Capacity (kg)  \n0         No       Tote  Green             20.671147  \n1        Yes   Backpack  Green             13.564105  \n2        Yes  Messenger   Blue             11.809799  \n3         No  Messenger  Green             18.477036  \n4        Yes       Tote  Black              9.907953  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Brand</th>\n      <th>Material</th>\n      <th>Size</th>\n      <th>Compartments</th>\n      <th>Laptop Compartment</th>\n      <th>Waterproof</th>\n      <th>Style</th>\n      <th>Color</th>\n      <th>Weight Capacity (kg)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>300000</td>\n      <td>Puma</td>\n      <td>Leather</td>\n      <td>Small</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Tote</td>\n      <td>Green</td>\n      <td>20.671147</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>300001</td>\n      <td>Nike</td>\n      <td>Canvas</td>\n      <td>Medium</td>\n      <td>7.0</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Backpack</td>\n      <td>Green</td>\n      <td>13.564105</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>300002</td>\n      <td>Adidas</td>\n      <td>Canvas</td>\n      <td>Large</td>\n      <td>9.0</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Messenger</td>\n      <td>Blue</td>\n      <td>11.809799</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>300003</td>\n      <td>Adidas</td>\n      <td>Nylon</td>\n      <td>Large</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Messenger</td>\n      <td>Green</td>\n      <td>18.477036</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>300004</td>\n      <td>NaN</td>\n      <td>Nylon</td>\n      <td>Large</td>\n      <td>2.0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Tote</td>\n      <td>Black</td>\n      <td>9.907953</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"df_train.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:49:51.506500Z","iopub.execute_input":"2025-02-28T04:49:51.506860Z","iopub.status.idle":"2025-02-28T04:49:51.585343Z","shell.execute_reply.started":"2025-02-28T04:49:51.506834Z","shell.execute_reply":"2025-02-28T04:49:51.584264Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"                  id   Compartments  Weight Capacity (kg)          Price\ncount  300000.000000  300000.000000         299862.000000  300000.000000\nmean   149999.500000       5.443590             18.029994      81.411107\nstd     86602.684716       2.890766              6.966914      39.039340\nmin         0.000000       1.000000              5.000000      15.000000\n25%     74999.750000       3.000000             12.097867      47.384620\n50%    149999.500000       5.000000             18.068614      80.956120\n75%    224999.250000       8.000000             24.002375     115.018160\nmax    299999.000000      10.000000             30.000000     150.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Compartments</th>\n      <th>Weight Capacity (kg)</th>\n      <th>Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>300000.000000</td>\n      <td>300000.000000</td>\n      <td>299862.000000</td>\n      <td>300000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>149999.500000</td>\n      <td>5.443590</td>\n      <td>18.029994</td>\n      <td>81.411107</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>86602.684716</td>\n      <td>2.890766</td>\n      <td>6.966914</td>\n      <td>39.039340</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>5.000000</td>\n      <td>15.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>74999.750000</td>\n      <td>3.000000</td>\n      <td>12.097867</td>\n      <td>47.384620</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>149999.500000</td>\n      <td>5.000000</td>\n      <td>18.068614</td>\n      <td>80.956120</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>224999.250000</td>\n      <td>8.000000</td>\n      <td>24.002375</td>\n      <td>115.018160</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>299999.000000</td>\n      <td>10.000000</td>\n      <td>30.000000</td>\n      <td>150.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"df_test.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:49:51.586484Z","iopub.execute_input":"2025-02-28T04:49:51.586837Z","iopub.status.idle":"2025-02-28T04:49:51.623290Z","shell.execute_reply.started":"2025-02-28T04:49:51.586812Z","shell.execute_reply":"2025-02-28T04:49:51.622474Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"                  id   Compartments  Weight Capacity (kg)\ncount  200000.000000  200000.000000         199923.000000\nmean   399999.500000       5.442855             17.993033\nstd     57735.171256       2.888740              6.972079\nmin    300000.000000       1.000000              5.000000\n25%    349999.750000       3.000000             12.068875\n50%    399999.500000       5.000000             18.054750\n75%    449999.250000       8.000000             23.965700\nmax    499999.000000      10.000000             30.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Compartments</th>\n      <th>Weight Capacity (kg)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>200000.000000</td>\n      <td>200000.000000</td>\n      <td>199923.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>399999.500000</td>\n      <td>5.442855</td>\n      <td>17.993033</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>57735.171256</td>\n      <td>2.888740</td>\n      <td>6.972079</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>300000.000000</td>\n      <td>1.000000</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>349999.750000</td>\n      <td>3.000000</td>\n      <td>12.068875</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>399999.500000</td>\n      <td>5.000000</td>\n      <td>18.054750</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>449999.250000</td>\n      <td>8.000000</td>\n      <td>23.965700</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>499999.000000</td>\n      <td>10.000000</td>\n      <td>30.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"df_train.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:49:51.625803Z","iopub.execute_input":"2025-02-28T04:49:51.626077Z","iopub.status.idle":"2025-02-28T04:49:51.740460Z","shell.execute_reply.started":"2025-02-28T04:49:51.626044Z","shell.execute_reply":"2025-02-28T04:49:51.739610Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 300000 entries, 0 to 299999\nData columns (total 11 columns):\n #   Column                Non-Null Count   Dtype  \n---  ------                --------------   -----  \n 0   id                    300000 non-null  int64  \n 1   Brand                 290295 non-null  object \n 2   Material              291653 non-null  object \n 3   Size                  293405 non-null  object \n 4   Compartments          300000 non-null  float64\n 5   Laptop Compartment    292556 non-null  object \n 6   Waterproof            292950 non-null  object \n 7   Style                 292030 non-null  object \n 8   Color                 290050 non-null  object \n 9   Weight Capacity (kg)  299862 non-null  float64\n 10  Price                 300000 non-null  float64\ndtypes: float64(3), int64(1), object(7)\nmemory usage: 25.2+ MB\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"df_test.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:49:51.742091Z","iopub.execute_input":"2025-02-28T04:49:51.742348Z","iopub.status.idle":"2025-02-28T04:49:51.821629Z","shell.execute_reply.started":"2025-02-28T04:49:51.742325Z","shell.execute_reply":"2025-02-28T04:49:51.820717Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 200000 entries, 0 to 199999\nData columns (total 10 columns):\n #   Column                Non-Null Count   Dtype  \n---  ------                --------------   -----  \n 0   id                    200000 non-null  int64  \n 1   Brand                 193773 non-null  object \n 2   Material              194387 non-null  object \n 3   Size                  195619 non-null  object \n 4   Compartments          200000 non-null  float64\n 5   Laptop Compartment    195038 non-null  object \n 6   Waterproof            195189 non-null  object \n 7   Style                 194847 non-null  object \n 8   Color                 193215 non-null  object \n 9   Weight Capacity (kg)  199923 non-null  float64\ndtypes: float64(2), int64(1), object(7)\nmemory usage: 15.3+ MB\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"df_train.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:49:51.822566Z","iopub.execute_input":"2025-02-28T04:49:51.822829Z","iopub.status.idle":"2025-02-28T04:49:51.828140Z","shell.execute_reply.started":"2025-02-28T04:49:51.822806Z","shell.execute_reply":"2025-02-28T04:49:51.827358Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"(300000, 11)"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"df_train.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:49:51.828943Z","iopub.execute_input":"2025-02-28T04:49:51.829153Z","iopub.status.idle":"2025-02-28T04:49:51.948771Z","shell.execute_reply.started":"2025-02-28T04:49:51.829134Z","shell.execute_reply":"2025-02-28T04:49:51.947791Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"id                         0\nBrand                   9705\nMaterial                8347\nSize                    6595\nCompartments               0\nLaptop Compartment      7444\nWaterproof              7050\nStyle                   7970\nColor                   9950\nWeight Capacity (kg)     138\nPrice                      0\ndtype: int64"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"df_train_clean = df_train.dropna(subset=['Laptop Compartment', 'Waterproof'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:49:51.949751Z","iopub.execute_input":"2025-02-28T04:49:51.950036Z","iopub.status.idle":"2025-02-28T04:49:52.004987Z","shell.execute_reply.started":"2025-02-28T04:49:51.950003Z","shell.execute_reply":"2025-02-28T04:49:52.004206Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"df_train_clean.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:49:52.005818Z","iopub.execute_input":"2025-02-28T04:49:52.006048Z","iopub.status.idle":"2025-02-28T04:49:52.110470Z","shell.execute_reply.started":"2025-02-28T04:49:52.006029Z","shell.execute_reply":"2025-02-28T04:49:52.109513Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"id                         0\nBrand                   9350\nMaterial                8098\nSize                    6369\nCompartments               0\nLaptop Compartment         0\nWaterproof                 0\nStyle                   7735\nColor                   9464\nWeight Capacity (kg)      49\nPrice                      0\ndtype: int64"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"unique_brand = df_train_clean['Brand'].unique().tolist()\ndf_train_clean['Brand'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:49:52.111491Z","iopub.execute_input":"2025-02-28T04:49:52.111817Z","iopub.status.idle":"2025-02-28T04:49:52.145697Z","shell.execute_reply.started":"2025-02-28T04:49:52.111788Z","shell.execute_reply":"2025-02-28T04:49:52.144626Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"Brand\nAdidas          57185\nUnder Armour    57019\nNike            54678\nPuma            53990\nJansport        53380\nName: count, dtype: int64"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"unique_Material=df_train_clean['Material'].unique().tolist()\ndf_train_clean['Material'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:49:52.146769Z","iopub.execute_input":"2025-02-28T04:49:52.147150Z","iopub.status.idle":"2025-02-28T04:49:52.193274Z","shell.execute_reply.started":"2025-02-28T04:49:52.147112Z","shell.execute_reply":"2025-02-28T04:49:52.192405Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"Material\nPolyester    75554\nLeather      69991\nNylon        67166\nCanvas       64793\nName: count, dtype: int64"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"unique_size=df_train_clean['Size'].unique().tolist()\nunique_size_counts = df_train_clean['Size'].value_counts()\nunique_size_counts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:49:52.194297Z","iopub.execute_input":"2025-02-28T04:49:52.194641Z","iopub.status.idle":"2025-02-28T04:49:52.243346Z","shell.execute_reply.started":"2025-02-28T04:49:52.194619Z","shell.execute_reply":"2025-02-28T04:49:52.242361Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"Size\nMedium    97016\nLarge     93798\nSmall     88419\nName: count, dtype: int64"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"df_train_clean['Style'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:49:52.244368Z","iopub.execute_input":"2025-02-28T04:49:52.244765Z","iopub.status.idle":"2025-02-28T04:49:52.284128Z","shell.execute_reply.started":"2025-02-28T04:49:52.244727Z","shell.execute_reply":"2025-02-28T04:49:52.283105Z"}},"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"Style\nMessenger    95241\nTote         92630\nBackpack     89996\nName: count, dtype: int64"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"df_train_clean['Color'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:49:52.285133Z","iopub.execute_input":"2025-02-28T04:49:52.285466Z","iopub.status.idle":"2025-02-28T04:49:52.320569Z","shell.execute_reply.started":"2025-02-28T04:49:52.285433Z","shell.execute_reply":"2025-02-28T04:49:52.319526Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"Color\nPink     49203\nGray     47903\nBlue     45731\nRed      44989\nBlack    44158\nGreen    44154\nName: count, dtype: int64"},"metadata":{}}],"execution_count":41},{"cell_type":"markdown","source":"Mode imputation for categorical columns","metadata":{}},{"cell_type":"code","source":"categorical_columns = ['Brand', 'Material', 'Size', 'Style', 'Color']\n\n# Apply mode imputation for each categorical column\nfor col in categorical_columns:\n    # Compute mode; mode() returns a Series so we select the first element [0]\n    mode_value = df_train_clean[col].mode()[0]\n    df_train_clean[col].fillna(mode_value, inplace=True)\n    \nprint(\"\\nDataFrame after mode imputation:\")\ndf_train_clean","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:49:52.321631Z","iopub.execute_input":"2025-02-28T04:49:52.321973Z","iopub.status.idle":"2025-02-28T04:49:52.519269Z","shell.execute_reply.started":"2025-02-28T04:49:52.321943Z","shell.execute_reply":"2025-02-28T04:49:52.518166Z"}},"outputs":[{"name":"stdout","text":"\nDataFrame after mode imputation:\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-42-a77d28e241d9>:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df_train_clean[col].fillna(mode_value, inplace=True)\n<ipython-input-42-a77d28e241d9>:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_train_clean[col].fillna(mode_value, inplace=True)\n","output_type":"stream"},{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"            id         Brand Material    Size  Compartments  \\\n0            0      Jansport  Leather  Medium           7.0   \n1            1      Jansport   Canvas   Small          10.0   \n2            2  Under Armour  Leather   Small           2.0   \n3            3          Nike    Nylon   Small           8.0   \n4            4        Adidas   Canvas  Medium           1.0   \n...        ...           ...      ...     ...           ...   \n299995  299995        Adidas  Leather   Small           9.0   \n299996  299996      Jansport  Leather   Large           6.0   \n299997  299997          Puma   Canvas   Large           9.0   \n299998  299998        Adidas    Nylon   Small           1.0   \n299999  299999  Under Armour   Canvas   Small           2.0   \n\n       Laptop Compartment Waterproof      Style  Color  Weight Capacity (kg)  \\\n0                     Yes         No       Tote  Black             11.611723   \n1                     Yes        Yes  Messenger  Green             27.078537   \n2                     Yes         No  Messenger    Red             16.643760   \n3                     Yes         No  Messenger  Green             12.937220   \n4                     Yes        Yes  Messenger  Green             17.749338   \n...                   ...        ...        ...    ...                   ...   \n299995                 No         No       Tote   Blue             12.730812   \n299996                 No        Yes       Tote   Blue             26.633182   \n299997                Yes        Yes   Backpack   Pink             11.898250   \n299998                 No        Yes       Tote   Pink              6.175738   \n299999                 No        Yes   Backpack  Black             18.568865   \n\n            Price  \n0       112.15875  \n1        68.88056  \n2        39.17320  \n3        80.60793  \n4        86.02312  \n...           ...  \n299995  129.99749  \n299996   19.85819  \n299997  111.41364  \n299998  115.89080  \n299999   26.72762  \n\n[285602 rows x 11 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Brand</th>\n      <th>Material</th>\n      <th>Size</th>\n      <th>Compartments</th>\n      <th>Laptop Compartment</th>\n      <th>Waterproof</th>\n      <th>Style</th>\n      <th>Color</th>\n      <th>Weight Capacity (kg)</th>\n      <th>Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Jansport</td>\n      <td>Leather</td>\n      <td>Medium</td>\n      <td>7.0</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Tote</td>\n      <td>Black</td>\n      <td>11.611723</td>\n      <td>112.15875</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Jansport</td>\n      <td>Canvas</td>\n      <td>Small</td>\n      <td>10.0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Messenger</td>\n      <td>Green</td>\n      <td>27.078537</td>\n      <td>68.88056</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Under Armour</td>\n      <td>Leather</td>\n      <td>Small</td>\n      <td>2.0</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Messenger</td>\n      <td>Red</td>\n      <td>16.643760</td>\n      <td>39.17320</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Nike</td>\n      <td>Nylon</td>\n      <td>Small</td>\n      <td>8.0</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Messenger</td>\n      <td>Green</td>\n      <td>12.937220</td>\n      <td>80.60793</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Adidas</td>\n      <td>Canvas</td>\n      <td>Medium</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Messenger</td>\n      <td>Green</td>\n      <td>17.749338</td>\n      <td>86.02312</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>299995</th>\n      <td>299995</td>\n      <td>Adidas</td>\n      <td>Leather</td>\n      <td>Small</td>\n      <td>9.0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Tote</td>\n      <td>Blue</td>\n      <td>12.730812</td>\n      <td>129.99749</td>\n    </tr>\n    <tr>\n      <th>299996</th>\n      <td>299996</td>\n      <td>Jansport</td>\n      <td>Leather</td>\n      <td>Large</td>\n      <td>6.0</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Tote</td>\n      <td>Blue</td>\n      <td>26.633182</td>\n      <td>19.85819</td>\n    </tr>\n    <tr>\n      <th>299997</th>\n      <td>299997</td>\n      <td>Puma</td>\n      <td>Canvas</td>\n      <td>Large</td>\n      <td>9.0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Backpack</td>\n      <td>Pink</td>\n      <td>11.898250</td>\n      <td>111.41364</td>\n    </tr>\n    <tr>\n      <th>299998</th>\n      <td>299998</td>\n      <td>Adidas</td>\n      <td>Nylon</td>\n      <td>Small</td>\n      <td>1.0</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Tote</td>\n      <td>Pink</td>\n      <td>6.175738</td>\n      <td>115.89080</td>\n    </tr>\n    <tr>\n      <th>299999</th>\n      <td>299999</td>\n      <td>Under Armour</td>\n      <td>Canvas</td>\n      <td>Small</td>\n      <td>2.0</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Backpack</td>\n      <td>Black</td>\n      <td>18.568865</td>\n      <td>26.72762</td>\n    </tr>\n  </tbody>\n</table>\n<p>285602 rows × 11 columns</p>\n</div>"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"df_train_clean.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:49:52.520462Z","iopub.execute_input":"2025-02-28T04:49:52.520761Z","iopub.status.idle":"2025-02-28T04:49:52.624778Z","shell.execute_reply.started":"2025-02-28T04:49:52.520736Z","shell.execute_reply":"2025-02-28T04:49:52.623890Z"}},"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"id                       0\nBrand                    0\nMaterial                 0\nSize                     0\nCompartments             0\nLaptop Compartment       0\nWaterproof               0\nStyle                    0\nColor                    0\nWeight Capacity (kg)    49\nPrice                    0\ndtype: int64"},"metadata":{}}],"execution_count":43},{"cell_type":"markdown","source":"Mean Imputation of numerical column","metadata":{}},{"cell_type":"code","source":"df_train_clean['Weight Capacity (kg)'].fillna(df_train_clean['Weight Capacity (kg)'].mean(),inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:49:52.625690Z","iopub.execute_input":"2025-02-28T04:49:52.626035Z","iopub.status.idle":"2025-02-28T04:49:52.635802Z","shell.execute_reply.started":"2025-02-28T04:49:52.626001Z","shell.execute_reply":"2025-02-28T04:49:52.634651Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-44-80c460f5c43b>:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df_train_clean['Weight Capacity (kg)'].fillna(df_train_clean['Weight Capacity (kg)'].mean(),inplace=True)\n<ipython-input-44-80c460f5c43b>:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_train_clean['Weight Capacity (kg)'].fillna(df_train_clean['Weight Capacity (kg)'].mean(),inplace=True)\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"df_train_clean.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:49:52.636902Z","iopub.execute_input":"2025-02-28T04:49:52.637251Z","iopub.status.idle":"2025-02-28T04:49:52.750061Z","shell.execute_reply.started":"2025-02-28T04:49:52.637214Z","shell.execute_reply":"2025-02-28T04:49:52.749002Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"id                      0\nBrand                   0\nMaterial                0\nSize                    0\nCompartments            0\nLaptop Compartment      0\nWaterproof              0\nStyle                   0\nColor                   0\nWeight Capacity (kg)    0\nPrice                   0\ndtype: int64"},"metadata":{}}],"execution_count":45},{"cell_type":"markdown","source":"# label encoding","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\ndef function labelencoding(df_train_clean):\n    le = LabelEncoder()\n    df_train_encoded=df_train_clean\n    df_train_encoded['Brand'] = le.fit_transform(df_train_clean['Brand'])\n    df_train_encoded['Material']=le.fit_transform(df_train_clean['Material'])\n    df_train_encoded['Size']=le.fit_transform(df_train_clean['Size'])\n    df_train_encoded['Waterproof']=le.fit_transform(df_train_clean['Waterproof'])\n    df_train_encoded['Color']=le.fit_transform(df_train_clean['Color'])\n    df_train_encoded['Style']=le.fit_transform(df_train_clean['Style'])\n    df_train_encoded['Laptop Compartment']=le.fit_transform(df_train_clean['Laptop Compartment'])\n    return df_train_encoded\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:49:52.753116Z","iopub.execute_input":"2025-02-28T04:49:52.753413Z","iopub.status.idle":"2025-02-28T04:49:52.760252Z","shell.execute_reply.started":"2025-02-28T04:49:52.753363Z","shell.execute_reply":"2025-02-28T04:49:52.758885Z"}},"outputs":[{"traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-46-fc70f28742b6>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def function labelencoding(df_train_clean):\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"],"ename":"SyntaxError","evalue":"invalid syntax (<ipython-input-46-fc70f28742b6>, line 1)","output_type":"error"}],"execution_count":46},{"cell_type":"code","source":"df_train_encoded=labelencoding(df_train_clean)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:49:52.761147Z","iopub.status.idle":"2025-02-28T04:49:52.761525Z","shell.execute_reply":"2025-02-28T04:49:52.761336Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# One Hot encoding","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import OneHotEncoder\n\ndef onehotencode(df_train_clean):\n   \n    encoder = OneHotEncoder(drop='first', sparse_output=False)  # drop='first' to avoid dummy variable trap\n    \n    # Selecting categorical columns\n    cat_cols = ['Brand', 'Material', 'Size', 'Compartments', 'Laptop Compartment',\n                'Waterproof', 'Style', 'Color']\n\n    # Ensure the categorical columns exist in the DataFrame\n    cat_cols = [col for col in cat_cols if col in df_train_clean.columns]\n\n    if not cat_cols:\n        print(\"No categorical columns found for encoding.\")\n        return df_train_clean  # Return original if no valid categorical columns\n\n    # Fit-transform categorical columns\n    encoded_array = encoder.fit_transform(df_train_clean[cat_cols])\n\n    # Create DataFrame with encoded values\n    encoded_df = pd.DataFrame(encoded_array, columns=encoder.get_feature_names_out(cat_cols))\n\n    # Concatenate with the original DataFrame (dropping original categorical columns)\n    df_final = pd.concat([df_train_clean.drop(columns=cat_cols), encoded_df], axis=1)\n\n    return df_final  # Returning the transformed DataFrame\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:50:08.640455Z","iopub.execute_input":"2025-02-28T04:50:08.640759Z","iopub.status.idle":"2025-02-28T04:50:09.164155Z","shell.execute_reply.started":"2025-02-28T04:50:08.640738Z","shell.execute_reply":"2025-02-28T04:50:09.163367Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"df_train_encoded=onehotencode(df_train_clean)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:50:12.133796Z","iopub.execute_input":"2025-02-28T04:50:12.134282Z","iopub.status.idle":"2025-02-28T04:50:13.062174Z","shell.execute_reply.started":"2025-02-28T04:50:12.134257Z","shell.execute_reply":"2025-02-28T04:50:13.061227Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"df_train_encoded.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:50:14.572222Z","iopub.execute_input":"2025-02-28T04:50:14.572581Z","iopub.status.idle":"2025-02-28T04:50:14.600906Z","shell.execute_reply.started":"2025-02-28T04:50:14.572555Z","shell.execute_reply":"2025-02-28T04:50:14.599661Z"}},"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"    id  Weight Capacity (kg)      Price  Brand_Jansport  Brand_Nike  \\\n0  0.0             11.611723  112.15875             1.0         0.0   \n1  1.0             27.078537   68.88056             1.0         0.0   \n2  2.0             16.643760   39.17320             0.0         0.0   \n3  3.0             12.937220   80.60793             0.0         1.0   \n4  4.0             17.749338   86.02312             0.0         0.0   \n\n   Brand_Puma  Brand_Under Armour  Material_Leather  Material_Nylon  \\\n0         0.0                 0.0               1.0             0.0   \n1         0.0                 0.0               0.0             0.0   \n2         0.0                 1.0               1.0             0.0   \n3         0.0                 0.0               0.0             1.0   \n4         0.0                 0.0               0.0             0.0   \n\n   Material_Polyester  ...  Compartments_10.0  Laptop Compartment_Yes  \\\n0                 0.0  ...                0.0                     1.0   \n1                 0.0  ...                1.0                     1.0   \n2                 0.0  ...                0.0                     1.0   \n3                 0.0  ...                0.0                     1.0   \n4                 0.0  ...                0.0                     1.0   \n\n   Waterproof_Yes  Style_Messenger  Style_Tote  Color_Blue  Color_Gray  \\\n0             0.0              0.0         1.0         0.0         0.0   \n1             1.0              1.0         0.0         0.0         0.0   \n2             0.0              1.0         0.0         0.0         0.0   \n3             0.0              1.0         0.0         0.0         0.0   \n4             1.0              1.0         0.0         0.0         0.0   \n\n   Color_Green  Color_Pink  Color_Red  \n0          0.0         0.0        0.0  \n1          1.0         0.0        0.0  \n2          0.0         0.0        1.0  \n3          1.0         0.0        0.0  \n4          1.0         0.0        0.0  \n\n[5 rows x 30 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Weight Capacity (kg)</th>\n      <th>Price</th>\n      <th>Brand_Jansport</th>\n      <th>Brand_Nike</th>\n      <th>Brand_Puma</th>\n      <th>Brand_Under Armour</th>\n      <th>Material_Leather</th>\n      <th>Material_Nylon</th>\n      <th>Material_Polyester</th>\n      <th>...</th>\n      <th>Compartments_10.0</th>\n      <th>Laptop Compartment_Yes</th>\n      <th>Waterproof_Yes</th>\n      <th>Style_Messenger</th>\n      <th>Style_Tote</th>\n      <th>Color_Blue</th>\n      <th>Color_Gray</th>\n      <th>Color_Green</th>\n      <th>Color_Pink</th>\n      <th>Color_Red</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>11.611723</td>\n      <td>112.15875</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>27.078537</td>\n      <td>68.88056</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.0</td>\n      <td>16.643760</td>\n      <td>39.17320</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.0</td>\n      <td>12.937220</td>\n      <td>80.60793</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.0</td>\n      <td>17.749338</td>\n      <td>86.02312</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 30 columns</p>\n</div>"},"metadata":{}}],"execution_count":49},{"cell_type":"code","source":"df_train_encoded.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:50:22.813873Z","iopub.execute_input":"2025-02-28T04:50:22.814208Z","iopub.status.idle":"2025-02-28T04:50:22.819233Z","shell.execute_reply.started":"2025-02-28T04:50:22.814181Z","shell.execute_reply":"2025-02-28T04:50:22.818490Z"}},"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"(299298, 30)"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"X_train = df_train_encoded.drop(columns=['Price'])  # 'Price' is the target column\ny_train = df_train_encoded['Price']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:57:16.236438Z","iopub.execute_input":"2025-02-28T04:57:16.236776Z","iopub.status.idle":"2025-02-28T04:57:16.269119Z","shell.execute_reply.started":"2025-02-28T04:57:16.236752Z","shell.execute_reply":"2025-02-28T04:57:16.268237Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import cross_val_score, KFold\nimport numpy as np\n\n# Define KFold cross-validation\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\n\n# Choose a model (RandomForestRegressor)\nmodel = RandomForestRegressor(n_estimators=100, random_state=42)\n\n# Perform cross-validation scoring\ncv_scores = cross_val_score(model, X_train, y_train, cv=kf, scoring='neg_mean_squared_error')\n\n# Convert negative MSE to RMSE\nrmse_scores = np.sqrt(-cv_scores)\n\nprint(f\"Cross-Validation RMSE Scores: {rmse_scores}\")\nprint(f\"Mean RMSE: {rmse_scores.mean()}\")\nprint(f\"Standard Deviation RMSE: {rmse_scores.std()}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T04:57:37.716588Z","iopub.execute_input":"2025-02-28T04:57:37.716961Z","iopub.status.idle":"2025-02-28T04:57:39.017845Z","shell.execute_reply.started":"2025-02-28T04:57:37.716931Z","shell.execute_reply":"2025-02-28T04:57:39.016273Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-53-998d7e8aa825>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Perform cross-validation scoring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mcv_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_mean_squared_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Convert negative MSE to RMSE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m     cv_results = cross_validate(\n\u001b[0m\u001b[1;32m    516\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    283\u001b[0m     )\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m     \u001b[0m_warn_or_raise_about_fit_failures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;31m# For callabe scoring, the return type is only know after calling. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0;34mf\"Below are more details about the failures:\\n{fit_errors_summary}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             )\n\u001b[0;32m--> 367\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_fits_failed_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\", line 345, in fit\n    X, y = self._validate_data(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 584, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 1106, in check_X_y\n    X = check_array(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n    _assert_all_finite(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nRandomForestRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"],"ename":"ValueError","evalue":"\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\", line 345, in fit\n    X, y = self._validate_data(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 584, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 1106, in check_X_y\n    X = check_array(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n    _assert_all_finite(\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nRandomForestRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n","output_type":"error"}],"execution_count":53},{"cell_type":"code","source":"model.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T05:00:44.324308Z","iopub.execute_input":"2025-02-28T05:00:44.324743Z","iopub.status.idle":"2025-02-28T05:00:44.494353Z","shell.execute_reply.started":"2025-02-28T05:00:44.324712Z","shell.execute_reply":"2025-02-28T05:00:44.492917Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-54-d768f88d541e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1104\u001b[0m         )\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1107\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             )\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nRandomForestRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"],"ename":"ValueError","evalue":"Input X contains NaN.\nRandomForestRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values","output_type":"error"}],"execution_count":54}]}